{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25e5615f",
   "metadata": {},
   "source": [
    "# Comparación de Modelos Supervisados con Validación Cruzada\n",
    "\n",
    "Notebook pensado para un público general. Cada sección explica qué se hace, por qué se hace y cómo interpretar los resultados. Caso económico: riesgo de crédito (Give Me Some Credit, Kaggle). Métrica principal: ROC AUC y partición 70/15/15 estratificada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14045d3c",
   "metadata": {},
   "source": [
    "## Contexto y decisiones de diseño\n",
    "- Objetivo: predecir morosidad seria en 2 años (SeriousDlqin2yrs).\n",
    "- Datos: más de 10 predictores numéricos (edad, ingresos, utilización de crédito, atrasos, etc.).\n",
    "- Decisiones: ROC AUC por desbalance, particiones estratificadas, pipelines sin fuga de información, comparación de tres modelos clásicos.\n",
    "- Criterio de éxito: mayor AUC promedio en CV y coherencia con el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1af5d0",
   "metadata": {},
   "source": [
    "## Guía de lectura\n",
    "1. Diagnóstico y EDA.\n",
    "2. Partición estratificada + pipeline reproducible.\n",
    "3. Validación cruzada y comparación de modelos.\n",
    "4. Selección y evaluación en prueba (ROC + matriz de confusión).\n",
    "5. Interpretaciones automáticas + resumen exportable al README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9475447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones y configuración\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid', context='notebook')\n",
    "plt.rcParams['figure.figsize'] = (8, 5)\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "DATA_PATH = Path('data')\n",
    "CSV_FILE = DATA_PATH / 'cs-training.csv'\n",
    "assert CSV_FILE.exists(), 'No se encontró data/cs-training.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61efb8d",
   "metadata": {},
   "source": [
    "## Dataset y objetivo\n",
    "- Qué: cargar cs-training.csv, definir variable objetivo y revisar faltantes.\n",
    "- Por qué: documentar el estado del dataset antes de entrenar y planear imputaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebeea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_FILE)\n",
    "if 'Unnamed: 0' in df.columns:\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "target = 'SeriousDlqin2yrs'\n",
    "features = [c for c in df.columns if c != target]\n",
    "\n",
    "print('Forma del dataset:', df.shape)\n",
    "display(df.head())\n",
    "miss = df.isna().sum().sort_values(ascending=False)\n",
    "display(pd.DataFrame({'faltantes': miss[miss > 0], '%': (miss[miss > 0] / len(df) * 100).round(2)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63100d3f",
   "metadata": {},
   "source": [
    "## EDA: distribución e implicaciones\n",
    "- Visualizamos el desbalance de la clase objetivo.\n",
    "- Exploramos histogramas de variables clave para detectar escalas y outliers.\n",
    "Interpretación: al haber desbalance evitamos depender de accuracy y usamos ROC AUC / PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9414571",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[target].value_counts().sort_index().plot(kind='bar', color=['#4C78A8', '#F58518'])\n",
    "ax.set_xticklabels(['No morosidad seria', 'Morosidad seria'])\n",
    "ax.set_ylabel('Número de observaciones')\n",
    "ax.set_title('Distribución de la clase objetivo')\n",
    "plt.show()\n",
    "\n",
    "cols = ['RevolvingUtilizationOfUnsecuredLines', 'age', 'DebtRatio', 'MonthlyIncome', 'NumberOfTimes90DaysLate']\n",
    "df[cols].hist(bins=30, figsize=(12, 6), color='#4C78A8')\n",
    "plt.suptitle('Distribuciones seleccionadas', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ae0a9",
   "metadata": {},
   "source": [
    "## Partición y pipeline\n",
    "- Partición 70/15/15 con estratificación en cada paso.\n",
    "- Pipeline: imputación (mediana) + StandardScaler aplicado a todas las variables numéricas.\n",
    "Beneficio: se evita fuga de información y todos los modelos reciben datos comparables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b1987",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features].copy()\n",
    "y = df[target].astype(int).copy()\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=SEED, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=SEED, stratify=y_temp\n",
    ")\n",
    "print({'train': len(X_train), 'val': len(X_val), 'test': len(X_test)})\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "preprocess = ColumnTransformer(transformers=[('num', numeric_transformer, features)])\n",
    "\n",
    "def make_pipeline(model):\n",
    "    return Pipeline([('prep', preprocess), ('model', model)])\n",
    "\n",
    "models = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(random_state=SEED),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba99af",
   "metadata": {},
   "source": [
    "## Validación cruzada (K=5)\n",
    "Qué: entrenamos cada modelo, registramos AUC en train/val y aplicamos StratifiedKFold. Cómo interpretar: cv_mean_auc ≈ desempeño esperado; cv_std_auc ≈ varianza entre folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def evaluate_model(name, estimator):\n",
    "    estimator.fit(X_train, y_train)\n",
    "    train_auc = roc_auc_score(y_train, estimator.predict_proba(X_train)[:, 1])\n",
    "    val_auc = roc_auc_score(y_val, estimator.predict_proba(X_val)[:, 1])\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    cv_scores = cross_val_score(estimator, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "    return {\n",
    "        'model': name,\n",
    "        'train_auc': train_auc,\n",
    "        'val_auc': val_auc,\n",
    "        'cv_mean_auc': float(cv_scores.mean()),\n",
    "        'cv_std_auc': float(cv_scores.std(ddof=1)),\n",
    "        'cv_scores': cv_scores,\n",
    "    }\n",
    "\n",
    "results = [evaluate_model(name, make_pipeline(model)) for name, model in models.items()]\n",
    "res = pd.DataFrame(results).sort_values('cv_mean_auc', ascending=False)\n",
    "res[['model', 'train_auc', 'val_auc', 'cv_mean_auc', 'cv_std_auc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fefde33",
   "metadata": {},
   "source": [
    "## Selección y evaluación en prueba\n",
    "Reentrenamos el mejor modelo con \train + val, medimos en \test y graficamos curva ROC + matriz de confusión (umbral 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf50b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = res.iloc[0]['model']\n",
    "best_estimator = make_pipeline(models[best])\n",
    "\n",
    "X_trainval = pd.concat([X_train, X_val])\n",
    "y_trainval = pd.concat([y_train, y_val])\n",
    "\n",
    "best_estimator.fit(X_trainval, y_trainval)\n",
    "y_test_proba = best_estimator.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, y_test_proba)\n",
    "print(f'Modelo seleccionado: {best}')\n",
    "print(f'ROC AUC en prueba: {auc:.3f}')\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC={auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('FPR (1 - Especificidad)')\n",
    "plt.ylabel('TPR (Sensibilidad)')\n",
    "plt.title('Curva ROC en conjunto de prueba')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(best_estimator, X_test, y_test, cmap='Blues')\n",
    "plt.title('Matriz de confusión (umbral 0.5)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb3efd5",
   "metadata": {},
   "source": [
    "## Interpretaciones automáticas\n",
    "Generamos texto con desbalance, faltantes y correlaciones principales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a64194",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_rate = y.mean()\n",
    "print(f'Proporción positiva (morosidad): {pos_rate:.2%}')\n",
    "if pos_rate < 0.1:\n",
    "    print('Desbalance severo: usar estratificación y métricas basadas en ranking.')\n",
    "elif pos_rate < 0.3:\n",
    "    print('Desbalance moderado: preferir ROC AUC y revisar umbrales.')\n",
    "else:\n",
    "    print('Clases relativamente balanceadas.')\n",
    "\n",
    "na = miss[miss > 0]\n",
    "if len(na):\n",
    "    print('Columnas con faltantes (imputadas con mediana dentro del pipeline):')\n",
    "    display(pd.DataFrame({'faltantes': na, '%': (na / len(df) * 100).round(2)}))\n",
    "else:\n",
    "    print('No se detectaron faltantes relevantes.')\n",
    "\n",
    "corr = df[features + [target]].corr(numeric_only=True)[target].drop(target).sort_values(ascending=False)\n",
    "print('Top correlaciones positivas con la morosidad:')\n",
    "display(corr.head(5))\n",
    "print('Top correlaciones negativas con la morosidad:')\n",
    "display(corr.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a522cd2f",
   "metadata": {},
   "source": [
    "## Resumen en Markdown\n",
    "Bloque autoexplicativo listo para pegar en informes o README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967cd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "cv_mean = float(res[res['model'] == best]['cv_mean_auc'].values[0])\n",
    "cv_std = float(res[res['model'] == best]['cv_std_auc'].values[0])\n",
    "summary_md = f''' \n",
    "### Resumen de hallazgos\n",
    "- Desbalance: proporción positiva = {pos_rate:.2%}. Estratificación + ROC AUC.\n",
    "- Faltantes: {int(na.sum()) if len(na) else 0} valores en {len(na)} columnas (imputación mediana).\n",
    "- Señales lineales: {', '.join(list(corr.head(3).index))} (positivas) y {', '.join(list(corr.tail(3).index))} (negativas).\n",
    "- Mejor modelo: **{best}** con CV AUC = {cv_mean:.3f} (+/- {cv_std:.3f}).\n",
    "- Prueba: AUC = {auc:.3f}; diferencia test − CV = {auc - cv_mean:+.3f}.\n",
    "- Interpretación: alta utilización de crédito y múltiples atrasos elevan el riesgo; mayor edad/ingresos tienden a mitigarlo.\n",
    "'''\n",
    "display(Markdown(summary_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee5df8",
   "metadata": {},
   "source": [
    "## Exportar resumen al README (opcional)\n",
    "Inserta o actualiza una sección marcada en README.md."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d519eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_marker = '<!-- AUTO-RESULTS-START -->'\n",
    "end_marker = '<!-- AUTO-RESULTS-END -->'\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "block = f\"\n",
    "\n",
    "{start_marker}\n",
    "## Resultados (autogenerado)\n",
    "\n",
    "Generado desde Trabajo2.ipynb el {timestamp}.\n",
    "\n",
    "{summary_md}\n",
    "{end_marker}\n",
    "\"\n",
    "\n",
    "readme_path = Path('README.md')\n",
    "if readme_path.exists():\n",
    "    txt = readme_path.read_text(encoding='utf-8', errors='ignore')\n",
    "    if start_marker in txt and end_marker in txt:\n",
    "        before = txt.split(start_marker)[0]\n",
    "        after = txt.split(end_marker)[-1]\n",
    "        new_text = before + block + after\n",
    "    else:\n",
    "        new_text = txt + block\n",
    "else:\n",
    "    new_text = '# README' + block\n",
    "\n",
    "readme_path.write_text(new_text, encoding='utf-8')\n",
    "print('Resumen de hallazgos escrito en README.md')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e347da",
   "metadata": {},
   "source": [
    "## Conclusiones y próximos pasos\n",
    "- Reportar el AUC de prueba junto con la media y desviación de CV.\n",
    "- Ajustar umbrales según costos y analizar la curva Precision‑Recall.\n",
    "- Explorar búsqueda de hiperparámetros o modelos ensemble y técnicas para lidiar con el desbalance (class_weight, SMOTE, undersampling).\n",
    "- Traducir las señales (utilización, atrasos) en políticas de crédito accionables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
